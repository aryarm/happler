import warnings
from pathlib import Path
import snakemake.io as io
from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("7.14.0")


# IMPORT CONFIG VARIABLES
configfile: "config/config.yml"


def check_config(value, default=False, place=config, as_set=False):
    """return true if config value exists and is true"""
    value = place[value] if (value in place and place[value]) else default
    return (set(value) if isinstance(value, list) else {value}) if as_set else value


# handle defaults
config["out"] = check_config("out", "out")
config["superpop"] = check_config("superpop", "EUR")
config["min_maf"] = check_config("min_maf", 0)
config["mode"] = check_config("mode", "snp", as_set=True)
config["beta"] = check_config("beta", 0.1, as_set=True)
config["exclude_causal"] = check_config("exclude_causal", False, as_set=True)
# remove any trailing slashes in directories and set the variables
out = str(Path(config["out"]))
logs = out + "/logs"
bench = out + "/bench"
# parse loci
loci = {loc["locus"].replace(":", "_"): loc for loc in config["loci"]}
# convert the exclude_causal var into a dict for later
exclude_causal = {("in", "ex")[val]: val for val in config["exclude_causal"]}


def get_vcf_chrs(vcf_path):
    """return a dict of VCFs split by contig"""
    if io.contains_wildcard(vcf_path):
        return glob_wildcards(vcf_path).chr
    return []


chrs = get_vcf_chrs(config["snp_panel"])


rule all:
    input:
        expand(
            out + "/{locus}/sim/{mode}/{beta}/{causal}clude/results/susie.pdf",
            locus=loci.keys(),
            beta=config["beta"],
            mode=config["mode"],
            causal=exclude_causal.keys(),
        ),


rule plink2vcf:
    """ convert a PLINK file to VCF """
    input:
        pgen=config["snp_panel"],
    params:
        pfile=lambda wildcards, input: str(Path(input.pgen).with_suffix('')),
        out=lambda wildcards, output: str(Path(output.bcf).with_suffix('')),
        start=lambda wildcards: wildcards.locus.split('-')[0],
        end=lambda wildcards: wildcards.locus.split('-')[1],
        chrom=lambda wildcards: wildcards.chr,
    output:
        vcf=temp(out + "/{chr}_{locus}/unphased.vcf.gz"),
        bcf=out + "/{chr}_{locus}/unphased.bcf",
        bcf_idx=out + "/{chr}_{locus}/unphased.bcf.csi",
        log=temp(out + "/{chr}_{locus}/unphased.log"),
    resources:
        runtime="0:15:00"
    log:
        logs + "/{chr}_{locus}/plink2vcf"
    benchmark:
        bench + "/{chr}_{locus}/plink2vcf"
    conda:
        "envs/default.yml"
    shell:
        "plink2 --pfile {params.pfile} --out {params.out} --from-bp {params.start} "
        "--to-bp {params.end} --chr {params.chrom} --snps-only 'just-acgt' "
        "--export vcf bgz id-paste=iid &>{log} && "
        "bcftools view -Ob -o {output.bcf} {output.vcf} &>>{log} && "
        "tabix -p bcf {output.bcf} &>>{log}"


def phase_gt_input(wildcards):
    input_files = { 'map': config['phase_map'] }
    if config["snp_panel"].endswith('.pgen'):
        input_files['unphased'] = rules.plink2vcf.output.bcf
    else:
        input_files['unphased'] = config["snp_panel"]
    input_files['unphased_idx'] = input_files['unphased'] + ".csi"
    return input_files


rule phase_gt:
    """ phase an unphased set of genotypes """
    input: unpack(phase_gt_input)
    params:
        locus=lambda wildcards: loci[wildcards.chr + "_" + wildcards.locus]["locus"],
    output:
        phased=out + "/{chr}_{locus}/phased.bcf",
        phased_idx=out + "/{chr}_{locus}/phased.bcf.csi",
    resources:
        runtime="4:00:00"
    threads: 8
    log:
        logs + "/{chr}_{locus}/phase_gt"
    benchmark:
        bench + "/{chr}_{locus}/phase_gt"
    conda:
        "envs/shapeit.yml"
    shell:
        "shapeit4 --input {input.unphased} --map {input.map} --region {params.locus} "
        "--output {output.phased} --thread {threads} --log {log} &>>{log} && "
        "tabix -p bcf {output.phased} &>>{log}"


rule keep_samps:
    """ create a list of the samples that we should keep """
    input:
        snp_vcf=lambda wildcards: rules.phase_gt.output.phased if check_config('phase_map')
            else config["snp_panel"],
        snp_vcf_idx=lambda wildcards: rules.phase_gt.output.phased_idx if check_config('phase_map')
            else config["snp_panel"] + ".tbi",
        str_vcf=config["str_panel"],
        str_vcf_idx=config["str_panel"],
        samp=config["exclude_samples"],
    output:
        samples=out+"/{chr}_{locus}/samples.tsv.gz"
    log:
        logs+"/{chr}_{locus}/keep_samps"
    conda:
        "envs/default.yml"
    shell:
        "workflow/scripts/keep_samps.bash {input.snp_vcf} {input.str_vcf} {input.samp}"
        " | gzip > {output.samples} 2>{log}"


rule vcf2gt:
    """ convert a VCF into a genotype matrix (cols are vars and rows are samples) """
    input:
        snp_vcf=lambda wildcards: rules.phase_gt.output.phased if check_config('phase_map')
            else config["snp_panel"],
        snp_vcf_idx=lambda wildcards: rules.phase_gt.output.phased_idx if check_config('phase_map')
            else config["snp_panel"] + ".tbi",
        str_vcf=config["str_panel"],
        str_vcf_idx=config["str_panel"],
        samples=rules.keep_samps.output.samples,
    params:
        locus=lambda wildcards: loci[wildcards.chr + "_" + wildcards.locus]["locus"],
    output:
        temp_snp=temp(out + "/{chr}_{locus}/snps.bcf"),
        temp_str=temp(out + "/{chr}_{locus}/strs.bcf"),
        matrix=out + "/{chr}_{locus}/matrix.tsv.gz",
    resources:
        runtime="1:45:00"
    log:
        logs + "/{chr}_{locus}/vcf2gt",
    benchmark:
        bench + "/{chr}_{locus}/vcf2gt",
    conda:
        "envs/default.yml"
    shell:
        "workflow/scripts/matrix.bash '{params.locus}' {input.snp_vcf} {input.str_vcf}"
        " {input.samples} {output.temp_snp} {output.temp_str} 2>{log} | gzip > {output.matrix}"


rule vcf2plink:
    """ convert a VCF into a PGEN file """
    input:
        vcf=lambda wildcards: expand(
            rules.vcf2gt.output.temp_snp,
            chr=wildcards.locus.split("_")[0],
            locus=wildcards.locus.split("_")[1],
        ),
    params:
        maf=config["min_maf"],
        prefix=lambda wildcards, output: Path(output.pgen).with_suffix(""),
    output:
        pgen=out+"/{locus}/snps.pgen",
        pvar=out+"/{locus}/snps.pvar",
        psam=out+"/{locus}/snps.psam",
        log=temp(out+"/{locus}/snps.log"),
    resources:
        runtime="0:30:00"
    log:
        logs + "/{locus}/vcf2plink",
    benchmark:
        bench + "/{locus}/vcf2plink",
    conda:
        "envs/default.yml"
    shell:
        "plink2 --bcf {input.vcf} --maf {params.maf} --make-pgen --out {params.prefix}"
        " &>{log}"


rule str2gt:
    """ sum the difference of each allele length from the reference allele length """
    input:
        matrix=lambda wildcards: expand(
            rules.vcf2gt.output.matrix,
            chr=wildcards.locus.split("_")[0],
            locus=wildcards.locus.split("_")[1],
        ),
    params:
        maf=config["min_maf"],
    output:
        matrix=out + "/{locus}/gt_matrix.tsv.gz",
    resources:
        runtime="2:00:00"
    log:
        logs + "/{locus}/str2gt",
    benchmark:
        bench + "/{locus}/str2gt",
    conda:
        "envs/default.yml"
    shell:
        "workflow/scripts/gt_matrix.py -o {output.matrix} -m {params.maf} {input.matrix} 2>{log}"


def phen_loc(wildcards):
    if config["mode"] == "snp":
        if "snp" in loci[wildcards.locus]:
            return "--snp-loc " + loci[wildcards.locus]["snp"].split(":")[1]
        return "--max-vars 1"
    else:
        return "--str-loc " + loci[wildcards.locus]["str"].split(":")[1]


rule phens:
    """ generate phenotypes from the genotype matrix """
    input:
        matrix=rules.str2gt.output,
    params:
        loc=phen_loc,
        beta=lambda wildcards: wildcards.beta,
        mode=lambda wildcards: wildcards.mode,
    output:
        phenotypes=out + "/{locus}/sim/{mode}/{beta}/phens.tsv.gz",
    log:
        logs + "/{locus}/sim/{mode}/{beta}/phens",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/phens",
    conda:
        "envs/default.yml"
    shell:
        "workflow/scripts/generate_phenotypes.py -o {output.phenotypes} "
        "--beta-{params.mode} {params.beta} {params.loc} -- {input.matrix} &>{log}"


rule phens2pheno:
    """ convert our custom 'phens' TSV file to a PLINK2 pheno file """
    input:
        phens=rules.phens.output.phenotypes,
    output:
        pheno=out + "/{locus}/sim/{mode}/{beta}/{locus}.pheno"
    wildcard_constraints:
        mode="snp|str",
    log:
        logs + "/{locus}/sim/{mode}/{beta}/pheno",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/pheno",
    conda:
        "envs/default.yml"
    shell:
        "zcat {input} | {{ read -r head; echo $head | "
        "sed 's/^sample\\t/#IID\t/' | cut -f-2; cut -f1,3 }} >{output} 2>{log}"


rule create_hap:
    """ create a hap file suitable for haptools transform and simphenotype """
    params:
        ignore="this", # the first parameter is always ignored for some reason
        chrom=lambda wildcards: wildcards.chr,
        locus=lambda wildcards: wildcards.locus.replace('-', '\t'),
        beta=lambda wildcards: wildcards.beta,
        alleles=lambda wildcards: loci[wildcards.chr + "_" + wildcards.locus]["hap"],
    output:
        hap=out + "/{chr}_{locus}/sim/hap/{beta}/{chr}_{locus}.hap"
    log:
        logs + "/{chr}_{locus}/sim/hap/{beta}/create_hap",
    benchmark:
        bench + "/{chr}_{locus}/sim/hap/{beta}/create_hap",
    conda:
        "envs/default.yml"
    script:
        "scripts/create_hap_file.sh"


rule transform:
    """ use the hap file to create a pgen of the haplotype """
    # note that we don't need to subset the samples here, b/c we did it above, anyway
    input:
        hap=lambda wildcards: expand(
            rules.create_hap.output.hap,
            chr=wildcards.locus.split("_")[0],
            locus=wildcards.locus.split("_")[1],
            beta=wildcards.beta,
        ),
        pgen=rules.vcf2plink.output.pgen,
        pvar=rules.vcf2plink.output.pvar,
        psam=rules.vcf2plink.output.psam,
    output:
        pgen=temp(out + "/{locus}/sim/hap/{beta}/{locus}.pgen"),
        pvar=temp(out + "/{locus}/sim/hap/{beta}/{locus}.pvar"),
        psam=temp(out + "/{locus}/sim/hap/{beta}/{locus}.psam"),
    log:
        logs + "/{locus}/sim/hap/{beta}/transform",
    benchmark:
        bench + "/{locus}/sim/hap/{beta}/transform",
    conda:
        "happler"
    shell:
        "haptools transform -o {output.pgen} {input.pgen} {input.hap} &>{log}"


rule simphenotype:
    """ use the hap file to create simulated phenotypes for the haplotype """
    input:
        hap=rules.transform.input.hap,
        pgen=rules.transform.output.pgen,
        pvar=rules.transform.output.pvar,
        psam=rules.transform.output.psam,
    output:
        pheno=out + "/{locus}/sim/hap/{beta}/{locus}.pheno",
    log:
        logs + "/{locus}/sim/hap/{beta}/simphenotype",
    benchmark:
        bench + "/{locus}/sim/hap/{beta}/simphenotype",
    conda:
        "happler"
    shell:
        "haptools simphenotype -o {output.pheno} {input.pgen} {input.hap} &>{log}"


rule pheno2phens:
    """ generate a phens file for a causal haplotype """
    input:
        pgen=rules.transform.output.pgen,
        pvar=rules.transform.output.pvar,
        psam=rules.transform.output.psam,
        pheno=rules.simphenotype.output.pheno,
    output:
        phens=out + "/{locus}/sim/hap/{beta}/phens.tsv.gz",
    log:
        logs + "/{locus}/sim/hap/{beta}/pheno2phens",
    benchmark:
        bench + "/{locus}/sim/hap/{beta}/pheno2phens",
    conda:
        "happler"
    shell:
        "workflow/scripts/pheno2phens.py -o {output.phens} {input.pgen} "
        "{input.pheno} &>{log}"


run_methods_out = out + "/{locus}/sim/{mode}/{beta}/{causal}clude/method_output"


rule run_methods:
    """run the methods FINEMAP and SuSie"""
    input:
        gt=rules.phens.input,
        phen=rules.phens.output,
    params:
        outdir=run_methods_out,
        exclude_causal=lambda wildcards: int(exclude_causal[wildcards.causal]),
    output:
        sumstats=temp(run_methods_out + "/sumstats.rds"),
        finemap=run_methods_out + "/finemap.rds",
        susie=run_methods_out + "/susie.rds",
    log:
        logs + "/{locus}/sim/{mode}/{beta}/{causal}clude/methods",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/{causal}clude/methods",
    conda:
        "envs/susie.yml"
    shell:
        "workflow/scripts/finemapping_methods.R {input} {params} &>{log}"


rule happler:
    """ execute happler! """
    input:
        gts=rules.vcf2plink.output.pgen,
        pts=lambda wildcards: rules.simphenotype.output.pheno \
            if wildcards.mode == "hap" else rules.phens2pheno.output.pheno,
    params:
        thresh=100,
        chunk_size=1000,
    output:
        hap=run_methods_out + "/happler.hap"
    resources:
        runtime="0:30:00",
        queue="hotel",
    threads: 6
    log:
        logs + "/{locus}/sim/{mode}/{beta}/{causal}clude/happler",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/{causal}clude/happler",
    conda:
        "happler"
    shell:
        "happler run -o {output.hap} --verbosity DEBUG --discard-multiallelic"
        " -t {params.thresh} --discard-missing --chunk-size {params.chunk_size} "
        "{input.gts} {input.pts} &>{log}"


rule transform_happler:
    input:
        hap=rules.happler.output.hap,
        pgen=rules.vcf2plink.output.pgen,
        pvar=rules.vcf2plink.output.pvar,
        psam=rules.vcf2plink.output.psam,
    params:
        hap_id="H1",
    output:
        pgen=temp(run_methods_out + "/happler.pgen"),
        pvar=temp(run_methods_out + "/happler.pvar"),
        psam=temp(run_methods_out + "/happler.psam"),
    resources:
        runtime="0:04:00"
    log:
        logs + "/{locus}/sim/{mode}/{beta}/{causal}clude/transform_happler",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/{causal}clude/transform_happler",
    conda:
        "happler"
    shell:
        "haptools transform -o {output.pgen} --id {params.hap_id} {input.pgen} "
        "{input.hap} &>{log}"


rule append_hap2mat:
    input:
        matrix=rules.phens.input,
        hps=rules.transform_happler.output.pgen,
        hps_pvar=rules.transform_happler.output.pvar,
        hps_psam=rules.transform_happler.output.psam,
    output:
        matrix=run_methods_out + "/happler.tsv.gz",
    resources:
        runtime="0:04:00"
    log:
        logs + "/{locus}/sim/{mode}/{beta}/{causal}clude/append_hap2mat",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/{causal}clude/append_hap2mat",
    conda:
        "happler"
    shell:
        "zcat {input.matrix} | paste - <(workflow/scripts/append_hap.py {input.hps} "
        "<(zcat {input.matrix} | cut -f1 | tail -n+2)) | gzip >{output.matrix} 2>{log}"


rule run_susie_happler:
    """ execute SuSiE using the haplotypes from happler """
    input:
        gt=rules.phens.input,
        phen=rules.phens.output,
    params:
        outdir=run_methods_out,
        exclude_causal=lambda wildcards: int(exclude_causal[wildcards.causal]),
    output:
        sumstats=temp(run_methods_out + "/sumstats.rds"),
        finemap=run_methods_out + "/finemap.rds",
        susie=run_methods_out + "/susie.rds",
    log:
        logs + "/{locus}/sim/{mode}/{beta}/{causal}clude/methods",
    benchmark:
        bench + "/{locus}/sim/{mode}/{beta}/{causal}clude/methods",
    conda:
        "envs/susie.yml"
    shell:
        "workflow/scripts/finemapping_methods.R {input} {params} &>{log}"


plot_results_out = out + "/{locus}/sim/{mode}/{beta}/{causal}clude/results"


rule plot_results:
    """create plots to summarize the results of the simulations"""
    input:
        gt=rules.phens.input,
        finemap=rules.run_methods.output.finemap,
        susie=rules.run_methods.output.susie,
    params:
        outdir=plot_results_out,
    output:
        finemap_pdf=plot_results_out + "/finemap.pdf",
        susie_pdf=plot_results_out + "/susie.pdf",
        # susie_eff_pdf=temp(plot_results_out + "/susie_eff.pdf"),
    log:
        logs + "/{locus}/sim/{mode}/{beta}/{causal}clude/results",
    conda:
        "envs/susie.yml"
    script:
        "scripts/summarize_results.R"
